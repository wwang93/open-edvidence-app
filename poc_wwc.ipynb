{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5272e94c",
   "metadata": {},
   "source": [
    "# RAG Research Summarizer with Claude (Proof of Concept)\n",
    "This script uses Anthropic's Claude to answer queries using relevant research summaries.\n",
    "\n",
    "## Setup:\n",
    "1. Add your API key to a file called ignore.py at the same directory level as this script:\n",
    "\n",
    "    KEY = \"your_claude_api_key_here\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf881731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qq torch sentence-transformers anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e298a7c2",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8000a0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jrosenb8/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jrosenb8/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import ignore\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import anthropic\n",
    "\n",
    "\n",
    "DOCUMENT_STORE_PATH: str = './all_wwc.json'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22617b3b",
   "metadata": {},
   "source": [
    "# extract documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5551ddec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dddm_pg_092909.pdf__41__0||Recommendation 4. Provide supports that foster a data-driven culture within the school\n",
      "( 35 )\n",
      "need to provide the same level of guidance \n",
      "and support as indicated earlier.\n",
      "2. Dedicate structured time for staff \n",
      "collaboration.\n",
      "Encouraging teachers to work collabora­\n",
      "tively with data helps make data use an \n",
      "established part of a school’s culture.96 \n",
      "Collaborative data analysis can highlight \n",
      "achievement patterns across grade levels, \n",
      "departments, or schools97 and can engen­\n",
      "der the kind of consistency of instructional \n",
      "practices and expectations that often char­\n",
      "acterizes high-performing schools.98 \n",
      "Structured time should be set aside for \n",
      "teachers and school staff to collabora­\n",
      "tively analyze and interpret their students’ \n",
      "achievement data, and to identify instruc­\n",
      "tional changes.99 This time also can be \n",
      "used for professional development on data \n",
      "use. Ideally, this structured time should \n",
      "occur a few times each week, depending \n",
      "on the individual school’s needs. It is im­\n",
      "portant that schools make these collabora­\n",
      "tive meetings a priority. \n",
      "Collaborative meeting participants can \n",
      "vary from school to school. Most fre­\n",
      "quently, data meetings occur among small \n",
      "groups of teachers in the same grade level \n",
      "or subject area. Other times, these meet­\n",
      "ings include some combination of teach­\n",
      "ers in the same grade level or subject \n",
      "area, a data facilitator, and/or other data \n",
      "team members. \n",
      "Because school schedule constraints vary, \n",
      "principals can explore different options\n",
      "\n",
      "\n",
      "dddm_pg_092909.pdf__41__1||ers in the same grade level or subject \n",
      "area, a data facilitator, and/or other data \n",
      "team members. \n",
      "Because school schedule constraints vary, \n",
      "principals can explore different options \n",
      "96.  Feldman and Tung (2001).\n",
      "97.  Cromey and Hanson (2000).\n",
      "98.  Bigger (2006); Herman and Gribbons (2001); \n",
      "Huffman and Kalnin (2003); Lachat and Smith \n",
      "(2005); Wayman, Cho, and Johnston (2007).\n",
      "99.  Anderegg (2007); Bigger (2006); Cromey and \n",
      "Hanson (2000); Gentry (2005); Herman and Grib­\n",
      "bons (2001); Huffman and Kalnin (2003); Ingram, \n",
      "Louis, and Schroeder (2004); Supovitz and Klein \n",
      "(2003); Wayman and Stringfield (2006). \n",
      "for scheduling collaborative time. For ex­\n",
      "ample, one school has dedicated biweekly \n",
      "two-hour meetings for staff to examine \n",
      "student data and identify next instruc­\n",
      "tional steps.100 Another school adjusted \n",
      "weekly class schedules to have a com­\n",
      "mon break for teachers to examine data \n",
      "collaboratively.101 \n",
      "The collaborative team meetings should \n",
      "include the following components:\n",
      "• Preparation. Prior to these meetings, \n",
      "educators should set an agenda that \n",
      "focuses on using the most updated \n",
      "data relative to a specific, timely topic. \n",
      "It is too overwhelming to attempt to \n",
      "address all student achievement con­\n",
      "cerns at once; targeted discussions are \n",
      "key to successful data meetings. \n",
      "• Analysis. During these meetings, \n",
      "teachers should follow the cycle of in­\n",
      "quiry, using data to state hypotheses \n",
      "about their teaching and learning prac­\n",
      "tices and then testing those hypoth­\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = json.load(open(DOCUMENT_STORE_PATH, 'r'))\n",
    "docs = [f'{k}||{v}' for k, v in docs.items()]  # Make them a list with some metadata fusion.\n",
    "\n",
    "for doc in docs[99:99+2]:  # print a few docs as an example\n",
    "    print(doc)\n",
    "    print(); print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34302a0e",
   "metadata": {},
   "source": [
    "# cosine similarity function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92af8a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_top_k(model: SentenceTransformer, query: str, doc_embs: torch.Tensor, docs: list[str], k: int = 3) -> list[tuple[float, str]]:\n",
    "    \"\"\"\n",
    "    Perform a cosine similarity search for a query against precomputed document embeddings.\n",
    "\n",
    "    Args:\n",
    "        model (SentenceTransformer): Preloaded Huggingface embedding model.\n",
    "        query (str): Query string.\n",
    "        doc_embs (torch.Tensor): Precomputed document embeddings (normalized).\n",
    "        docs (List[str]): Original documents corresponding to embeddings.\n",
    "        k (int, optional): Number of top results to return. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        list[Tuple[float, str]]: List of (similarity_score, document) tuples.\n",
    "    \"\"\"\n",
    "    query_emb = model.encode([query], convert_to_tensor=True, normalize_embeddings=True)\n",
    "    sims = util.cos_sim(query_emb, doc_embs)[0]  # shape: [num_docs]\n",
    "    top_k = torch.topk(sims, k=k)\n",
    "    return [(score.item(), docs[idx]) for idx, score in zip(top_k.indices, top_k.values)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b34cce6",
   "metadata": {},
   "source": [
    "# build model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2855932",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "doc_embs = model.encode(docs, convert_to_tensor=True, normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d26b30a",
   "metadata": {},
   "source": [
    "### example search usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9dd3a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5972 | wwc_STEM_FFO_IR_mar2020.pdf__3__1||review of all fraction concepts including part–whole concept and measurement interpretations of fractions.\n",
      "Activities\n",
      "Each lesson includes four activities: a warm-up word problem, group work during which the teacher demonstrates fraction \n",
      "concepts using explicit instruction, a speed game to build fluency, and a worksheet activity that students complete individually \n",
      "to check their understanding of the fraction concepts. The program involves frequent use of fluency practice using speed tests \n",
      "or flashcards, and conceptual practice requiring students to explain their reasoning about fractions to the group. The program \n",
      "includes ongoing assessment through daily worksheets and a cumulative review during the final three lessons. The program \n",
      "has embedded motivation through a sports theme and a football challenge at the end of the program. \n",
      "Recommended dosage\n",
      "The developer recommends three 30- to 35-minute lessons per week for 12 weeks. \n",
      "Training \n",
      "Fraction Face-Off! includes up to a week of training for teachers before delivering content to students. In the training \n",
      "workshop, the trainer presents an overview of the program goals and procedures. Procedures are then modeled and \n",
      "practiced for each activity in the first set of topics. Teachers have opportunities to practice techniques and activities in pairs \n",
      "and receive feedback. Once teachers begin delivering Fraction Face-Off!, they attend 1-hour meetings every other week to\n",
      "\n",
      "0.5856 | WWC2021006-Math-PG.pdf__14__2||the example that demonstrate steps in this \n",
      "recommendation are bolded.\n",
      "In this example, the learning outcome that \n",
      "has been identified for the small group of 3–6 \n",
      "students is multi-digit division. The equal-sized \n",
      "groups model of multiplication and division has \n",
      "been built incrementally and intentionally over \n",
      "multiple lessons using correct mathematical \n",
      "language and visual representations. Students \n",
      "have demonstrated understanding of the equal-\n",
      "sized groups model and how it relates to both \n",
      "multiplication and division. Now, the students \n",
      "are ready to learn how to apply this model \n",
      "to solve multi-digit division problems. The \n",
      "teacher plans to launch her lesson by reviewing \n",
      "students’ prior knowledge of multiplication \n",
      "and division concepts to lead into the lesson on \n",
      "multi-digit division.\n",
      "\n",
      "0.5490 | fractions_pg_093010.pdf__43__0||Recommendation 4 continued \n",
      "How to carry out the recommendation \n",
      "1.  Develop students’ understanding of proportional relations before teaching computa­\n",
      "tional procedures that are conceptually difficult to understand (e.g., cross-multiplication). \n",
      "Build on students’ developing strategies for solving ratio, rate, and proportion problems. \n",
      "Opportunities for students to solve ratio, rate, \n",
      "and proportion problems should be provided \n",
      "prior to teaching the cross-multiplication \n",
      "algorithm.122 Teachers can use a progression \n",
      "of problems that builds on students’ develop­\n",
      "ing strategies for proportional reasoning.123 In \n",
      "particular, teachers can initially pose problems \n",
      "that allow solutions via the buildup and unit \n",
      "ratio strategies and progress to problems that \n",
      "are easier to solve through cross multiplication. \n",
      "Encouraging students to apply their own strate­\n",
      "gies, discussing with students varied strate­\n",
      "gies’ strengths and weaknesses, and helping \n",
      "students understand why a problem’s solution \n",
      "is correct are advisable.124 If students do not \n",
      "generate these strategies on their own, teach­\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = 'how do I best teach long division?'\n",
    "n = 3\n",
    "\n",
    "results = search_top_k(model, query, doc_embs, docs, k=n)\n",
    "\n",
    "for score, doc in results:\n",
    "    print(f\"{score:.4f} | {doc}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a167ffd",
   "metadata": {},
   "source": [
    "# prompt building and generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b27dd541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(query: str, sources: int = 3, print_flag: bool = False) -> str:\n",
    "    results = search_top_k(model, query, doc_embs, docs, k=sources)\n",
    "\n",
    "    if print_flag:\n",
    "        for score, doc in results:\n",
    "            print(f\"{score:.4f} | {doc}\")\n",
    "\n",
    "\n",
    "    rag_input = {\n",
    "        \"query\": query,\n",
    "        \"research_summaries\": [\n",
    "            {\n",
    "                \"score\": score,\n",
    "                \"id\": text.split('||')[0],\n",
    "                \"text\": text.split('||')[1]\n",
    "            }\n",
    "            for score, text in results[:n]\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI assisntant that uses retrieval augmented generation to answer questions about educational best practices\n",
    "\n",
    "    == Relevant Information ==\n",
    "    Reference Summaries: You will be provided with structured summaries of research papers.\n",
    "    Relevance Filtering: Only use information from the summaries if it is directly relevant to the query.\n",
    "    Answer Generation: Generate concise, accurate, and clear answers to the user query.\n",
    "    Citation: When using information from a summary, include a reference to the summary’s ID.\n",
    "\n",
    "    ==INPUT==\n",
    "    {json.dumps(rag_input, indent=2)}\n",
    "\n",
    "    ==EXAMPLE OUTPUT== \n",
    "    {{\n",
    "    \"answer\": <\"Answer based on relevant summaries.\">,\n",
    "    \"used_summaries\": <[\"id1\", ..., \"idn\"]>\n",
    "    }}\n",
    "\n",
    "    ==IMPORTANT==\n",
    "    - Only respond with the output JSON, nothing before or after; DO NOT inlude \"```json\" or other markdown in your response.\n",
    "    - Maintain a professional and friendly tone.\n",
    "    - Respond only by referencing the given input. If none of the input is relevant to the user query, then respond that you have nothing useful to say.\n",
    "    - Do not elaborate at all in your response outside of the input data.\n",
    "    - Be concise\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd59cbeb",
   "metadata": {},
   "source": [
    "### putting it all together with claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dd6cd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': \"Based on the research summaries provided, there are references to class size studies, particularly Tennessee's Class Size Study (Project STAR) conducted by Finn and Achilles. This research examined questions about class size and student achievement. However, the summaries provided do not contain specific details about what the optimal class size is or the study's conclusions about ideal class sizes. One summary mentions that analyzing class size effects must account for not only class size itself but also teacher practices that correlate with class size variations. To provide specific recommendations about optimal class size, I would need access to summaries that contain the actual findings and conclusions from these studies.\", 'used_summaries': ['10236.pdf__181__0', '11112.pdf__118__0']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = generate_prompt(query='Tell me about optimal class size?')\n",
    "\n",
    "client = anthropic.Anthropic(api_key=ignore.KEY)\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=\"claude-sonnet-4-5-20250929\",    \n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "response_obj = json.loads(response.content[0].text)\n",
    "\n",
    "print(response_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48c2cb9",
   "metadata": {},
   "source": [
    "# A more production style oop example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708591ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGPromptGenerator:\n",
    "    def __init__(self, docs: list[str], api_key: str, embedding_model: str = \"all-MiniLM-L6-v2\", claude_model: str = \"claude-sonnet-4-5-20250929\"):\n",
    "        \"\"\"Initialize the RAG prompt generator and embed the documents.\n",
    "\n",
    "        Args:\n",
    "            docs: List of documents with format \"id||text\".\n",
    "            embedding_model: Name of the SentenceTransformer model to use for embeddings.\n",
    "            claude_model: Which Claude model to use.\n",
    "        \"\"\"\n",
    "        self.docs = docs\n",
    "        self.model = SentenceTransformer(embedding_model)\n",
    "        self.doc_embs = self.model.encode(docs, convert_to_tensor=True, normalize_embeddings=True)\n",
    "        self.claude_model = claude_model\n",
    "        self.client = anthropic.Anthropic(api_key=api_key)\n",
    "\n",
    "    def search_top_k(self, query: str, k: int = 3) -> list[tuple[float, str]]:\n",
    "        \"\"\"Perform a cosine similarity search for a query against precomputed document embeddings.\"\"\"\n",
    "        query_emb = self.model.encode([query], convert_to_tensor=True, normalize_embeddings=True)\n",
    "        sims = util.cos_sim(query_emb, self.doc_embs)[0]\n",
    "        top_k = torch.topk(sims, k=k)\n",
    "        return [(score.item(), self.docs[idx]) for idx, score in zip(top_k.indices, top_k.values)]\n",
    "\n",
    "    def generate_prompt(self, query: str, sources: int = 3, print_flag: bool = False) -> str:\n",
    "        \"\"\"Generate a RAG-style prompt with top-k relevant research summaries.\"\"\"\n",
    "        results = self.search_top_k(query, k=sources)\n",
    "\n",
    "        if print_flag:\n",
    "            for score, doc in results:\n",
    "                print(f\"{score:.4f} | {doc}\")\n",
    "\n",
    "        rag_input = {\n",
    "            \"query\": query,\n",
    "            \"research_summaries\": [\n",
    "                {\n",
    "                    \"score\": score,\n",
    "                    \"id\": text.split('||')[0],\n",
    "                    \"text\": text.split('||')[1]\n",
    "                }\n",
    "                for score, text in results[:sources]\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        You are an AI assistant that uses retrieval-augmented generation to answer questions about educational best practices.\n",
    "\n",
    "        == Relevant Information ==\n",
    "        Reference Summaries: You will be provided with structured summaries of research papers.\n",
    "        Relevance Filtering: Only use information from the summaries if it is directly relevant to the query. You may use mutliple summaries if they are all relevant.\n",
    "        Answer Generation: Generate concise, accurate, and clear answers to the user query.\n",
    "        Citation: When using information from a summary, include a reference to the summary IDs - inline when they are used.\n",
    "\n",
    "        ==INPUT==\n",
    "        {json.dumps(rag_input, indent=2)}\n",
    "\n",
    "        ==EXAMPLE OUTPUT==\n",
    "        {{\n",
    "        \"answer\": <\"Answer based on relevant summaries.\">,\n",
    "        \"used_summaries\": <[\"id1\", ..., \"idn\"]>,\n",
    "        \"all_summaries\": <[\"id1\", ..., \"idn\"]>\n",
    "        }}\n",
    "\n",
    "        ==IMPORTANT==\n",
    "        - Only respond with the output JSON, nothing before or after; DO NOT inlude \"```json\" or other markdown in your response.\n",
    "        - Maintain a professional and friendly tone.\n",
    "        - Respond only by referencing the given input. If none of the input is relevant to the user query, then respond that you have nothing useful to say.\n",
    "        - Do not elaborate at all in your response outside of the input data.\n",
    "        - Be concise\n",
    "\n",
    "        *REMEBER* \n",
    "        - Your response **must be valid JSON only**.\n",
    "        - DO NOT include ```json, ``` or any other markdown syntax.\n",
    "        - Do NOT include explanations, greetings, or extra text—only the JSON.\n",
    "        \"\"\"\n",
    "        return prompt\n",
    "\n",
    "    def query_llm(self, query: str, sources: int = 3, print_flag: bool = False) -> dict:\n",
    "        \"\"\"\n",
    "        Full pipeline: query -> retrieve top summaries -> generate prompt -> call Claude -> return JSON.\n",
    "        \"\"\"\n",
    "        prompt = self.generate_prompt(query, sources=sources, print_flag=print_flag)\n",
    "\n",
    "        response = self.client.messages.create(\n",
    "            model=self.claude_model,\n",
    "            max_tokens=1024,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            response = response.content[0].text.strip(r'```json').strip(r'```')\n",
    "            response_obj = json.loads(response)\n",
    "        except json.JSONDecodeError:\n",
    "            response_obj = {\"error\": \"Failed to parse response JSON\", \"raw_text\": response}\n",
    "\n",
    "        return response_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6276bda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research on optimal class size has been extensively studied, with the Tennessee class-size study being one of the most important experiments in this area (10236.pdf__81__0). The Tennessee study was a randomized experiment designed to determine whether reducing class size improves student achievement (10236.pdf__81__0). The study found that students in smaller classes of 13-17 students outperformed their peers in larger classes by a small margin on average (10236.pdf__87__0). The study eliminated all possible known explanations except for reduced class size when comparing achievement outcomes (10236.pdf__87__0). While there were some complications, such as about 10% of students moving out of their originally assigned class size condition, subsequent analyses suggested these issues did not affect the main conclusion that smaller class size caused slight improvements in achievement (10236.pdf__87__0). Meta-analyses of class size research have shown mixed results, with some reviews finding small improvements in achievement with class size reduction (10236.pdf__81__0), while others have not found consistent evidence of positive effects. Researchers have also investigated the causal mechanisms through which reduced class size affects achievement, using classroom observations, interviews, and ethnographic studies to understand the foundational processes at work (10236.pdf__134__1).\n",
      "--------------------------------------------------\n",
      "{\n",
      "  \"answer\": \"Research on optimal class size has been extensively studied, with the Tennessee class-size study being one of the most important experiments in this area (10236.pdf__81__0). The Tennessee study was a randomized experiment designed to determine whether reducing class size improves student achievement (10236.pdf__81__0). The study found that students in smaller classes of 13-17 students outperformed their peers in larger classes by a small margin on average (10236.pdf__87__0). The study eliminated all possible known explanations except for reduced class size when comparing achievement outcomes (10236.pdf__87__0). While there were some complications, such as about 10% of students moving out of their originally assigned class size condition, subsequent analyses suggested these issues did not affect the main conclusion that smaller class size caused slight improvements in achievement (10236.pdf__87__0). Meta-analyses of class size research have shown mixed results, with some reviews finding small improvements in achievement with class size reduction (10236.pdf__81__0), while others have not found consistent evidence of positive effects. Researchers have also investigated the causal mechanisms through which reduced class size affects achievement, using classroom observations, interviews, and ethnographic studies to understand the foundational processes at work (10236.pdf__134__1).\",\n",
      "  \"used_summaries\": [\n",
      "    \"10236.pdf__81__0\",\n",
      "    \"10236.pdf__87__0\",\n",
      "    \"10236.pdf__134__1\"\n",
      "  ],\n",
      "  \"all_summaries\": [\n",
      "    \"10236.pdf__181__0\",\n",
      "    \"10236.pdf__79__0\",\n",
      "    \"10236.pdf__134__1\",\n",
      "    \"10236.pdf__130__0\",\n",
      "    \"10236.pdf__81__0\",\n",
      "    \"10236.pdf__87__0\",\n",
      "    \"11112.pdf__118__0\",\n",
      "    \"12521.pdf__121__0\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "rag_generator = RAGPromptGenerator(docs, \n",
    "                                   api_key=ignore.KEY,\n",
    "                                   embedding_model='all-MiniLM-L6-v2', \n",
    "                                   claude_model='claude-sonnet-4-5-20250929')\n",
    "\n",
    "query = \"What do we know about optimal class size?\"\n",
    "response = rag_generator.query_llm(query, sources=8)\n",
    "\n",
    "print(response['answer'])\n",
    "print('-' * 50)\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6013a799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To help students who speak English as a second language, research-based recommendations include:\n",
      "\n",
      "1. **Teach academic vocabulary intensively** across several days using varied instructional activities (english_learners_pg_040114.pdf__10__1).\n",
      "\n",
      "2. **Integrate oral and written English instruction into content-area teaching**, which benefits both English learners and native English speakers from similar backgrounds (english_learners_pg_040114.pdf__10__1, english_learners_pg_040114.pdf__53__0).\n",
      "\n",
      "3. **Provide regular, structured opportunities to develop written language skills** (english_learners_pg_040114.pdf__10__1).\n",
      "\n",
      "4. **Offer small-group instructional interventions** (3-5 students) for students struggling with literacy and English language development. Use homogeneous groups for foundational skills like phonemic awareness and decoding, but heterogeneous groups for writing, oral language, and comprehension tasks (english_learners_pg_040114.pdf__10__1, english_learners_pg_040114.pdf__69__0).\n",
      "\n",
      "5. **Schedule peer-assisted learning opportunities**, with about 90 minutes per week of structured pair activities in reading and language arts (20074011.pdf__20__0).\n",
      "\n",
      "6. **Dedicate specific daily time blocks** to building academic English and provide teachers with appropriate professional development (20074011.pdf__20__0).\n",
      "--------------------------------------------------\n",
      "{\n",
      "  \"answer\": \"To help students who speak English as a second language, research-based recommendations include:\\n\\n1. **Teach academic vocabulary intensively** across several days using varied instructional activities (english_learners_pg_040114.pdf__10__1).\\n\\n2. **Integrate oral and written English instruction into content-area teaching**, which benefits both English learners and native English speakers from similar backgrounds (english_learners_pg_040114.pdf__10__1, english_learners_pg_040114.pdf__53__0).\\n\\n3. **Provide regular, structured opportunities to develop written language skills** (english_learners_pg_040114.pdf__10__1).\\n\\n4. **Offer small-group instructional interventions** (3-5 students) for students struggling with literacy and English language development. Use homogeneous groups for foundational skills like phonemic awareness and decoding, but heterogeneous groups for writing, oral language, and comprehension tasks (english_learners_pg_040114.pdf__10__1, english_learners_pg_040114.pdf__69__0).\\n\\n5. **Schedule peer-assisted learning opportunities**, with about 90 minutes per week of structured pair activities in reading and language arts (20074011.pdf__20__0).\\n\\n6. **Dedicate specific daily time blocks** to building academic English and provide teachers with appropriate professional development (20074011.pdf__20__0).\",\n",
      "  \"used_summaries\": [\n",
      "    \"english_learners_pg_040114.pdf__53__0\",\n",
      "    \"english_learners_pg_040114.pdf__10__1\",\n",
      "    \"english_learners_pg_040114.pdf__69__0\",\n",
      "    \"20074011.pdf__20__0\"\n",
      "  ],\n",
      "  \"all_summaries\": [\n",
      "    \"english_learners_pg_040114.pdf__53__0\",\n",
      "    \"english_learners_pg_040114.pdf__10__1\",\n",
      "    \"english_learners_pg_040114.pdf__69__0\",\n",
      "    \"20074011.pdf__20__0\",\n",
      "    \"20074011.pdf__17__0\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = \"How can I help my students who speak english as a second language?\"\n",
    "response = rag_generator.query_llm(query, sources=5)\n",
    "\n",
    "print(response['answer'])\n",
    "print('-' * 50)\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7287d07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the available research summaries, there is limited information directly addressing meditation outside for students. One reference mentions that outdoor education experiences may contribute to positive development in the affective domain [13362.pdf__262__1], but this pertains to general outdoor education rather than meditation specifically. The summaries provided do not contain sufficient research-based evidence to determine whether meditating outside would be useful to your students.\n",
      "--------------------------------------------------\n",
      "{\n",
      "  \"answer\": \"Based on the available research summaries, there is limited information directly addressing meditation outside for students. One reference mentions that outdoor education experiences may contribute to positive development in the affective domain [13362.pdf__262__1], but this pertains to general outdoor education rather than meditation specifically. The summaries provided do not contain sufficient research-based evidence to determine whether meditating outside would be useful to your students.\",\n",
      "  \"used_summaries\": [\n",
      "    \"13362.pdf__262__1\"\n",
      "  ],\n",
      "  \"all_summaries\": [\n",
      "    \"13362.pdf__228__0\",\n",
      "    \"13362.pdf__262__1\",\n",
      "    \"behavioral-interventions-practice-guide_v3a_508a.pdf__73__2\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = \"Would meditating outside be useful to my students?\"\n",
    "response = rag_generator.query_llm(query, sources=3)\n",
    "\n",
    "print(response['answer'])\n",
    "print('-' * 50)\n",
    "print(json.dumps(response, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
